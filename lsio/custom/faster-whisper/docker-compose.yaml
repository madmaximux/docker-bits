# [Faster-whisper](https://github.com/SYSTRAN/faster-whisper) is a
# reimplementation of OpenAI's Whisper model using CTranslate2, which is a fast
# inference engine for Transformer models. This container provides a Wyoming
# protocol server for faster-whisper.

---

services:
  faster-whisper:
    image: ghcr.io/linuxserver/faster-whisper
    container_name: faster-whisper
    environment:
      - PUID=${PUID:-1024}
      - PGID=${PGID:-100}
      - UMASK=${UMASK:-002}
      - TZ=${TZ:-America/Chicago}
      - WHISPER_MODEL=tiny-int8
      # - WHISPER_BEAM=1 # optional
      # - WHISPER_LANG=en # optional
    volumes:
      - ${DOCKERCONFIGPATH:-/volume1/docker/appdata}/faster-whisper${DOCKERCONFIGDIR:-}:/config
    # ports:
      # Wyoming connection port.
      # - 10300:10300
    networks:
      default:
        aliases:
          - faster-whisper
    restart: unless-stopped

networks:
  default:
    name: ${NETWORK_NAME:-synobridge}